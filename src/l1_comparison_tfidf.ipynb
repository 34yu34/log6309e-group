{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1LVUbGqd99IXywTxbc3QotpSyE8pWMcCx","authorship_tag":"ABX9TyNwJDm+YVeSMIvCUFRdCJFv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9DVvsknx8zvI","executionInfo":{"status":"ok","timestamp":1697525542139,"user_tz":240,"elapsed":579,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"719d8281-8e52-4af3-be64-94ca26441e34"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'drive/MyDrive/Code/GroupProjectDevops/log6309e-group/src'\n","/content/drive/MyDrive/Code/GroupProjectDevops/log6309e-group/src\n"]}],"source":["%cd drive/MyDrive/Code/GroupProjectDevops/log6309e-group/src"]},{"cell_type":"code","source":["from splitdatabgl import split_bgl\n","from extensions.stat_ranking import ModelData\n","from models.traditional import SVM\n","from models.traditional import DecisionTree\n","from models.traditional import LR\n","from models.MLP import MLP\n","from models.MLP_l1 import MLP_L1\n","import pandas as pd\n","import numpy as np"],"metadata":{"id":"YshFcfID9SlE","executionInfo":{"status":"ok","timestamp":1697525555218,"user_tz":240,"elapsed":13081,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["data = np.load('../data/BGL/text-tfidf-template-BGL.log.structured2_l1.npz')\n","train_x = data['x_train']\n","train_y = data['y_train']\n","test_x = data['x_test']\n","test_y = data['y_test']\n","\n","train_l1_x = data['x_train_l1']\n","train_l1_y = data['y_train_l1']\n","test_l1_x = data['x_test_l1']\n","test_l1_y = data['y_test_l1']"],"metadata":{"id":"lUsLDeS69Tfv","executionInfo":{"status":"ok","timestamp":1697525559001,"user_tz":240,"elapsed":3791,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["print(test_y.shape)\n","print(train_y.shape)\n","print(test_x.shape)\n","print(train_x.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5aTuJ2B3XQr6","executionInfo":{"status":"ok","timestamp":1697525559003,"user_tz":240,"elapsed":49,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"373c57ae-5376-4eb6-bff7-0ec03a0a7d9f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["(41,)\n","(163,)\n","(41, 1066)\n","(163, 1066)\n"]}]},{"cell_type":"code","source":["print(test_l1_y.shape)\n","print(train_l1_y.shape)\n","print(test_l1_x.shape)\n","print(train_l1_x.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hBf2mtIKXKzv","executionInfo":{"status":"ok","timestamp":1697525559003,"user_tz":240,"elapsed":37,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"3a1afbb7-6390-4465-efc3-3c8afe3c19eb"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["(41,)\n","(163,)\n","(41, 3)\n","(163, 3)\n"]}]},{"cell_type":"code","source":["def lr_model_eval(x_train, y_train, x_test, y_test):\n","    lr = LR(max_iter=100000)\n","    lr.fit(train_x, train_y)\n","    return lr.evaluate(test_x, test_y)\n","\n","def decision_tree_model_eval(x_train, y_train, x_test, y_test):\n","    decision_tree = DecisionTree()\n","    decision_tree.fit(train_x, train_y)\n","    return decision_tree.evaluate(test_x, test_y)\n","\n","def SVM_model_eval(x_train, y_train, x_test, y_test):\n","    svm = SVM(train_x, train_y, test_x, test_y)\n","    return svm.evaluate()"],"metadata":{"id":"HdzGBRmR9pnX","executionInfo":{"status":"ok","timestamp":1697525559003,"user_tz":240,"elapsed":31,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["lr_eval = lr_model_eval(train_x, train_y, test_x, test_y)\n","lr_l1_eval = lr_model_eval(train_l1_x, train_l1_y, test_l1_x, test_l1_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dz7kLO489yu9","executionInfo":{"status":"ok","timestamp":1697525559003,"user_tz":240,"elapsed":31,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"8b591261-6df7-438e-9409-566f756d83c1"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["====== Model summary ======\n","====== Evaluation summary ======\n","Precision: 0.875, recall: 1.000, F1-measure: 0.933\n","\n","====== Model summary ======\n","====== Evaluation summary ======\n","Precision: 0.875, recall: 1.000, F1-measure: 0.933\n","\n"]}]},{"cell_type":"code","source":["decision_tree_eval = decision_tree_model_eval(train_x, train_y, test_x, test_y)\n","decision_tree_l1_eval = decision_tree_model_eval(train_l1_x, train_l1_y, test_l1_x, test_l1_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"soJROQ5K-bWb","executionInfo":{"status":"ok","timestamp":1697525559004,"user_tz":240,"elapsed":27,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"21040612-98dc-436b-ede5-e6d533ca31d1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["====== Model summary ======\n","====== Evaluation summary ======\n","Precision: 1.000, recall: 0.943, F1-measure: 0.971\n","\n","====== Model summary ======\n","====== Evaluation summary ======\n","Precision: 1.000, recall: 0.943, F1-measure: 0.971\n","\n"]}]},{"cell_type":"code","source":["SVM_eval = SVM_model_eval(train_x, train_y, test_x, test_y)\n","SVM_l1_eval = SVM_model_eval(train_l1_x, train_l1_y, test_l1_x, test_l1_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IbBUABcD-bwQ","executionInfo":{"status":"ok","timestamp":1697525559350,"user_tz":240,"elapsed":370,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"2fba7150-b03e-4340-d164-d7250b40dbd9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","average:  0.8285714285714286 0.90625 0.8656716417910447\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","average:  0.8285714285714286 0.90625 0.8656716417910447\n"]}]},{"cell_type":"code","source":["mlp = MLP('../data/BGL/text-tfidf-template-BGL.log.structured2.npz')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4RUTWHwpi3lg","executionInfo":{"status":"ok","timestamp":1697525560519,"user_tz":240,"elapsed":1174,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"35e67d4b-9297-411c-f0b3-18769506686c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["(163, 1066)\n","(163,)\n","positive: 141\n","ratio: 1.1560283687943262\n","Net(\n","  (hidden1): Linear(in_features=1066, out_features=200, bias=True)\n","  (hidden2): Linear(in_features=200, out_features=200, bias=True)\n","  (output): Linear(in_features=200, out_features=2, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["loss_list, precision_list, recall_list, f1_list, accuracy_list = mlp.train_eval()"],"metadata":{"id":"_wGa-n8Gj1Y1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697525577136,"user_tz":240,"elapsed":16621,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"c320570f-5306-4f19-debd-a14adb2c9216"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["itr: 0, loss: 0.487801\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 10, loss: 0.397349\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 20, loss: 0.394096\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 30, loss: 0.393936\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 40, loss: 0.390961\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 50, loss: 0.384496\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 60, loss: 0.372089\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 70, loss: 0.345431\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 80, loss: 0.309327\n","Testset: Precision: 0.875, recall: 1.000, F1-measure: 0.933, acc:0.878\n","\n","itr: 90, loss: 0.280224\n","Testset: Precision: 0.875, recall: 1.000, F1-measure: 0.933, acc:0.878\n","\n","itr: 100, loss: 0.256091\n","Testset: Precision: 0.875, recall: 1.000, F1-measure: 0.933, acc:0.878\n","\n","itr: 110, loss: 0.232709\n","Testset: Precision: 0.872, recall: 0.971, F1-measure: 0.919, acc:0.854\n","\n","itr: 120, loss: 0.210996\n","Testset: Precision: 0.872, recall: 0.971, F1-measure: 0.919, acc:0.854\n","\n","itr: 130, loss: 0.197100\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 140, loss: 0.179402\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 150, loss: 0.163368\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 160, loss: 0.156804\n","Testset: Precision: 0.895, recall: 0.971, F1-measure: 0.932, acc:0.878\n","\n","itr: 170, loss: 0.144342\n","Testset: Precision: 0.895, recall: 0.971, F1-measure: 0.932, acc:0.878\n","\n","itr: 180, loss: 0.137654\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 190, loss: 0.136789\n","Testset: Precision: 0.895, recall: 0.971, F1-measure: 0.932, acc:0.878\n","\n","itr: 200, loss: 0.121544\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 210, loss: 0.118519\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 220, loss: 0.112032\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 230, loss: 0.113054\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 240, loss: 0.100864\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 250, loss: 0.101033\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 260, loss: 0.093134\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 270, loss: 0.092555\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 280, loss: 0.086619\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 290, loss: 0.083528\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 300, loss: 0.086338\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 310, loss: 0.078312\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 320, loss: 0.074380\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 330, loss: 0.071251\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 340, loss: 0.068666\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 350, loss: 0.066587\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 360, loss: 0.063660\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 370, loss: 0.071695\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 380, loss: 0.060697\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 390, loss: 0.059460\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 400, loss: 0.057485\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 410, loss: 0.061259\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 420, loss: 0.054406\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 430, loss: 0.060258\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 440, loss: 0.063604\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 450, loss: 0.051005\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 460, loss: 0.052359\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 470, loss: 0.048958\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 480, loss: 0.048495\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 490, loss: 0.046518\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 500, loss: 0.051952\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 510, loss: 0.053611\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 520, loss: 0.048849\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 530, loss: 0.044586\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 540, loss: 0.043469\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 550, loss: 0.041005\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 560, loss: 0.054420\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 570, loss: 0.047990\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 580, loss: 0.049426\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 590, loss: 0.038287\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 600, loss: 0.038765\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 610, loss: 0.037212\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 620, loss: 0.035978\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 630, loss: 0.035208\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 640, loss: 0.040197\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 650, loss: 0.038216\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 660, loss: 0.047633\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 670, loss: 0.034097\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 680, loss: 0.032355\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 690, loss: 0.031719\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 700, loss: 0.032042\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 710, loss: 0.033059\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 720, loss: 0.032259\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 730, loss: 0.032142\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 740, loss: 0.030971\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 750, loss: 0.030528\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 760, loss: 0.030386\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 770, loss: 0.028316\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 780, loss: 0.033578\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 790, loss: 0.027059\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 800, loss: 0.032852\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 810, loss: 0.027118\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 820, loss: 0.027965\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 830, loss: 0.025240\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 840, loss: 0.029886\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 850, loss: 0.024477\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 860, loss: 0.029006\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 870, loss: 0.023702\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 880, loss: 0.023964\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 890, loss: 0.025924\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 900, loss: 0.029844\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 910, loss: 0.022312\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 920, loss: 0.027202\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 930, loss: 0.021697\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 940, loss: 0.021816\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 950, loss: 0.027037\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 960, loss: 0.021840\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 970, loss: 0.022818\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 980, loss: 0.019997\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 990, loss: 0.020020\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1000, loss: 0.028892\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1010, loss: 0.022791\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 1020, loss: 0.018832\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1030, loss: 0.021644\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1040, loss: 0.019214\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1050, loss: 0.018004\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1060, loss: 0.018660\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1070, loss: 0.022181\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1080, loss: 0.020937\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 1090, loss: 0.016952\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1100, loss: 0.018051\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1110, loss: 0.019612\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1120, loss: 0.016323\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1130, loss: 0.015879\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1140, loss: 0.015925\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1150, loss: 0.029708\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1160, loss: 0.019625\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 1170, loss: 0.015685\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1180, loss: 0.014831\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1190, loss: 0.015297\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1200, loss: 0.014292\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1210, loss: 0.014059\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1220, loss: 0.014682\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1230, loss: 0.025642\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1240, loss: 0.018198\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 1250, loss: 0.015070\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1260, loss: 0.013496\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1270, loss: 0.012823\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1280, loss: 0.012734\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1290, loss: 0.012418\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1300, loss: 0.012306\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1310, loss: 0.013538\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1320, loss: 0.023387\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 1330, loss: 0.013935\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1340, loss: 0.011608\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1350, loss: 0.011891\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1360, loss: 0.011346\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1370, loss: 0.011010\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1380, loss: 0.010823\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1390, loss: 0.010657\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1400, loss: 0.010496\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1410, loss: 0.010335\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1420, loss: 0.010175\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1430, loss: 0.010020\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1440, loss: 0.009868\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1450, loss: 0.009725\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1460, loss: 0.009785\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1470, loss: 0.038458\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1480, loss: 0.607005\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 1490, loss: 0.110543\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1500, loss: 0.034969\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1510, loss: 0.034947\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1520, loss: 0.024060\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 1530, loss: 0.020729\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1540, loss: 0.017860\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1550, loss: 0.015590\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1560, loss: 0.014254\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1570, loss: 0.013369\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1580, loss: 0.012744\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1590, loss: 0.012275\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1600, loss: 0.011885\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1610, loss: 0.011546\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1620, loss: 0.011248\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1630, loss: 0.010981\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1640, loss: 0.010740\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1650, loss: 0.010520\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1660, loss: 0.010316\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1670, loss: 0.010123\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1680, loss: 0.009938\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1690, loss: 0.009759\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1700, loss: 0.009586\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1710, loss: 0.009420\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1720, loss: 0.009259\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1730, loss: 0.009105\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1740, loss: 0.008956\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1750, loss: 0.008812\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1760, loss: 0.008673\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1770, loss: 0.008540\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1780, loss: 0.008411\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1790, loss: 0.008286\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1800, loss: 0.008166\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1810, loss: 0.008051\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1820, loss: 0.007939\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1830, loss: 0.007831\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1840, loss: 0.007727\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1850, loss: 0.007625\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1860, loss: 0.007527\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1870, loss: 0.007432\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1880, loss: 0.007339\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1890, loss: 0.007249\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1900, loss: 0.007161\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1910, loss: 0.007074\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1920, loss: 0.006989\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1930, loss: 0.006907\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1940, loss: 0.006825\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1950, loss: 0.006745\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1960, loss: 0.006667\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1970, loss: 0.006590\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1980, loss: 0.006515\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1990, loss: 0.006441\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n"]}]},{"cell_type":"code","source":["print(precision_list[-1])\n","print(recall_list[-1])\n","print(f1_list[-1])\n","print(accuracy_list[-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9tLO1e4ukOmC","executionInfo":{"status":"ok","timestamp":1697525577136,"user_tz":240,"elapsed":21,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"76549fab-c7c8-40eb-e847-db0b7f07c1b2"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9411764705882353\n","0.9142857142857143\n","0.9275362318840579\n","tensor(0.8780)\n"]}]},{"cell_type":"code","source":["mlp_l1 = MLP_L1('../data/BGL/text-tfidf-template-BGL.log.structured2_l1.npz')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"cx9encJdSuIB","executionInfo":{"status":"error","timestamp":1697525578502,"user_tz":240,"elapsed":1376,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"d20af16d-d5bf-472f-a6fa-13c2252e08d0"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["(163, 3)\n","(163,)\n","positive: 140\n","ratio: 1.1642857142857144\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-7c1a9945ff19>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP_L1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/BGL/text-tfidf-template-BGL.log.structured2_l1.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/MyDrive/Code/GroupProjectDevops/log6309e-group/src/models/MLP_l1.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_path)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfea_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: scatter(): Expected dtype int64 for index"]}]},{"cell_type":"code","source":["loss_list, precision_list, recall_list, f1_list, accuracy_list = mlp.train_eval()"],"metadata":{"id":"Orv0leS3TyyF","executionInfo":{"status":"aborted","timestamp":1697525578503,"user_tz":240,"elapsed":10,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(precision_list[-1])\n","print(recall_list[-1])\n","print(f1_list[-1])\n","print(accuracy_list[-1])"],"metadata":{"id":"neiRpl8hT6YC","executionInfo":{"status":"aborted","timestamp":1697525578503,"user_tz":240,"elapsed":9,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}}},"execution_count":null,"outputs":[]}]}