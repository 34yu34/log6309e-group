{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1LVUbGqd99IXywTxbc3QotpSyE8pWMcCx","authorship_tag":"ABX9TyMppjyxYt/UaDAKVCIIbhwY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9DVvsknx8zvI","executionInfo":{"status":"ok","timestamp":1697930667887,"user_tz":240,"elapsed":558,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"1a778f47-2a97-4071-d270-138f5a48c389"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code/GroupProjectDevops/log6309e-group/src\n"]}],"source":["%cd drive/MyDrive/Code/GroupProjectDevops/log6309e-group/src"]},{"cell_type":"code","source":["from splitdatabgl import split_bgl\n","from extensions.stat_ranking import ModelData\n","from models.traditional import SVM\n","from models.traditional import DecisionTree\n","from models.traditional import LR\n","from models.MLP import MLP\n","from models.MLP_l1 import MLP_L1\n","import pandas as pd\n","import numpy as np"],"metadata":{"id":"YshFcfID9SlE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = np.load('../data/BGL/text-tfidf-template-BGL.log.structured2_l1.npz')\n","train_x = data['x_train']\n","train_y = data['y_train']\n","test_x = data['x_test']\n","test_y = data['y_test']\n","\n","train_l1_x = data['x_train_l1']\n","train_l1_y = data['y_train_l1'].astype(int)\n","test_l1_x = data['x_test_l1']\n","test_l1_y = data['y_test_l1'].astype(int)"],"metadata":{"id":"lUsLDeS69Tfv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(test_y.shape)\n","print(train_y.shape)\n","print(test_x.shape)\n","print(train_x.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5aTuJ2B3XQr6","executionInfo":{"status":"ok","timestamp":1697930679298,"user_tz":240,"elapsed":19,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"71c39768-3e08-4e4c-c441-7300589e51aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(41,)\n","(163,)\n","(41, 1066)\n","(163, 1066)\n"]}]},{"cell_type":"code","source":["print(test_l1_y.shape)\n","print(train_l1_y.shape)\n","print(test_l1_x.shape)\n","print(train_l1_x.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hBf2mtIKXKzv","executionInfo":{"status":"ok","timestamp":1697930679299,"user_tz":240,"elapsed":15,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"e2f6a873-41a1-4a45-fd18-2fb02d92503c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(41,)\n","(163,)\n","(41, 2)\n","(163, 2)\n"]}]},{"cell_type":"code","source":["def lr_model_eval(x_train, y_train, x_test, y_test):\n","    lr = LR(max_iter=100000)\n","    lr.fit(train_x, train_y)\n","    return lr.evaluate(test_x, test_y)\n","\n","def decision_tree_model_eval(x_train, y_train, x_test, y_test):\n","    decision_tree = DecisionTree()\n","    decision_tree.fit(train_x, train_y)\n","    return decision_tree.evaluate(test_x, test_y)\n","\n","def SVM_model_eval(x_train, y_train, x_test, y_test):\n","    svm = SVM(train_x, train_y, test_x, test_y)\n","    return svm.evaluate()"],"metadata":{"id":"HdzGBRmR9pnX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lr_eval = lr_model_eval(train_x, train_y, test_x, test_y)\n","lr_l1_eval = lr_model_eval(train_l1_x, train_l1_y, test_l1_x, test_l1_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dz7kLO489yu9","executionInfo":{"status":"ok","timestamp":1697930679299,"user_tz":240,"elapsed":9,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"04ae32e3-ce2b-49a8-ea8e-b9ca4c33469f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["====== Model summary ======\n","====== Evaluation summary ======\n","Precision: 0.875, recall: 1.000, F1-measure: 0.933\n","\n","====== Model summary ======\n","====== Evaluation summary ======\n","Precision: 0.875, recall: 1.000, F1-measure: 0.933\n","\n"]}]},{"cell_type":"code","source":["decision_tree_eval = decision_tree_model_eval(train_x, train_y, test_x, test_y)\n","decision_tree_l1_eval = decision_tree_model_eval(train_l1_x, train_l1_y, test_l1_x, test_l1_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"soJROQ5K-bWb","executionInfo":{"status":"ok","timestamp":1697930679453,"user_tz":240,"elapsed":10,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"fb5621f5-265b-40a1-b554-7e81c133482a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["====== Model summary ======\n","====== Evaluation summary ======\n","Precision: 1.000, recall: 0.943, F1-measure: 0.971\n","\n","====== Model summary ======\n","====== Evaluation summary ======\n","Precision: 1.000, recall: 0.943, F1-measure: 0.971\n","\n"]}]},{"cell_type":"code","source":["SVM_eval = SVM_model_eval(train_x, train_y, test_x, test_y)\n","SVM_l1_eval = SVM_model_eval(train_l1_x, train_l1_y, test_l1_x, test_l1_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IbBUABcD-bwQ","executionInfo":{"status":"ok","timestamp":1697930679602,"user_tz":240,"elapsed":156,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"5f5e8722-f30a-4468-84dd-a0313b8acd4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","average:  0.8285714285714286 0.90625 0.8656716417910447\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","Precision: 0.829, recall: 0.906, F1-measure: 0.866\n","\n","average:  0.8285714285714286 0.90625 0.8656716417910447\n"]}]},{"cell_type":"code","source":["mlp = MLP('../data/BGL/text-tfidf-template-BGL.log.structured2.npz')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4RUTWHwpi3lg","executionInfo":{"status":"ok","timestamp":1697930680821,"user_tz":240,"elapsed":1371,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"653463ea-f0c4-47d3-d87d-7e3823b0c470"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(163, 1066)\n","(163,)\n","positive: 141\n","ratio: 1.1560283687943262\n","Net(\n","  (hidden1): Linear(in_features=1066, out_features=200, bias=True)\n","  (hidden2): Linear(in_features=200, out_features=200, bias=True)\n","  (output): Linear(in_features=200, out_features=2, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["loss_list, precision_list, recall_list, f1_list, accuracy_list = mlp.train_eval()"],"metadata":{"id":"_wGa-n8Gj1Y1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697930695484,"user_tz":240,"elapsed":14668,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"e55c670b-1d81-4ea0-8141-5a99addcba01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["itr: 0, loss: 1.045411\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 10, loss: 0.395089\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 20, loss: 0.394406\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 30, loss: 0.394261\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 40, loss: 0.392945\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 50, loss: 0.389148\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 60, loss: 0.383635\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 70, loss: 0.375145\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 80, loss: 0.360987\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 90, loss: 0.337497\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 100, loss: 0.310821\n","Testset: Precision: 0.854, recall: 1.000, F1-measure: 0.921, acc:0.854\n","\n","itr: 110, loss: 0.286625\n","Testset: Precision: 0.875, recall: 1.000, F1-measure: 0.933, acc:0.878\n","\n","itr: 120, loss: 0.266500\n","Testset: Precision: 0.875, recall: 1.000, F1-measure: 0.933, acc:0.878\n","\n","itr: 130, loss: 0.246651\n","Testset: Precision: 0.872, recall: 0.971, F1-measure: 0.919, acc:0.854\n","\n","itr: 140, loss: 0.227932\n","Testset: Precision: 0.872, recall: 0.971, F1-measure: 0.919, acc:0.854\n","\n","itr: 150, loss: 0.210169\n","Testset: Precision: 0.872, recall: 0.971, F1-measure: 0.919, acc:0.854\n","\n","itr: 160, loss: 0.193940\n","Testset: Precision: 0.895, recall: 0.971, F1-measure: 0.932, acc:0.878\n","\n","itr: 170, loss: 0.178418\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 180, loss: 0.165899\n","Testset: Precision: 0.895, recall: 0.971, F1-measure: 0.932, acc:0.878\n","\n","itr: 190, loss: 0.151521\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 200, loss: 0.137622\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 210, loss: 0.126585\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 220, loss: 0.117847\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 230, loss: 0.109673\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 240, loss: 0.102845\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 250, loss: 0.097384\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 260, loss: 0.093953\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 270, loss: 0.091059\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 280, loss: 0.086986\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 290, loss: 0.082926\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 300, loss: 0.080309\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 310, loss: 0.078854\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 320, loss: 0.075608\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 330, loss: 0.072370\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 340, loss: 0.070539\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 350, loss: 0.067802\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 360, loss: 0.069999\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 370, loss: 0.066388\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 380, loss: 0.062638\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 390, loss: 0.061707\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 400, loss: 0.061646\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 410, loss: 0.057795\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 420, loss: 0.057708\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 430, loss: 0.057133\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 440, loss: 0.053378\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 450, loss: 0.056501\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 460, loss: 0.053001\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 470, loss: 0.049722\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 480, loss: 0.053375\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 490, loss: 0.048654\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 500, loss: 0.046692\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 510, loss: 0.048316\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 520, loss: 0.044627\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 530, loss: 0.045993\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 540, loss: 0.043104\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 550, loss: 0.046014\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 560, loss: 0.043072\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 570, loss: 0.040466\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 580, loss: 0.042003\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 590, loss: 0.038854\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 600, loss: 0.040831\n","Testset: Precision: 0.917, recall: 0.943, F1-measure: 0.930, acc:0.878\n","\n","itr: 610, loss: 0.037491\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 620, loss: 0.041832\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 630, loss: 0.036516\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 640, loss: 0.037090\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 650, loss: 0.035138\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 660, loss: 0.037935\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 670, loss: 0.034496\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 680, loss: 0.034018\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 690, loss: 0.032812\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 700, loss: 0.035307\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 710, loss: 0.032277\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 720, loss: 0.031701\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 730, loss: 0.030412\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 740, loss: 0.034552\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 750, loss: 0.029892\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 760, loss: 0.029811\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 770, loss: 0.028138\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 780, loss: 0.032807\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 790, loss: 0.027338\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 800, loss: 0.028136\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 810, loss: 0.026126\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 820, loss: 0.028935\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 830, loss: 0.025172\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 840, loss: 0.027046\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 850, loss: 0.024306\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 860, loss: 0.024118\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 870, loss: 0.028962\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 880, loss: 0.024244\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 890, loss: 0.022837\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 900, loss: 0.022564\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 910, loss: 0.024809\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 920, loss: 0.021309\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 930, loss: 0.021851\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 940, loss: 0.022570\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 950, loss: 0.020466\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 960, loss: 0.021953\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 970, loss: 0.019552\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 980, loss: 0.019150\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 990, loss: 0.021514\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 1000, loss: 0.018436\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1010, loss: 0.019569\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1020, loss: 0.017701\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1030, loss: 0.017995\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1040, loss: 0.019195\n","Testset: Precision: 0.943, recall: 0.943, F1-measure: 0.943, acc:0.902\n","\n","itr: 1050, loss: 0.016878\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1060, loss: 0.016760\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1070, loss: 0.018546\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1080, loss: 0.016213\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1090, loss: 0.016168\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1100, loss: 0.016373\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1110, loss: 0.015370\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1120, loss: 0.014964\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1130, loss: 0.015846\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1140, loss: 0.016655\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1150, loss: 0.015078\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1160, loss: 0.013792\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1170, loss: 0.013858\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1180, loss: 0.013503\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1190, loss: 0.013412\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1200, loss: 0.015236\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1210, loss: 0.013332\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1220, loss: 0.013337\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1230, loss: 0.012402\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1240, loss: 0.012067\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1250, loss: 0.011847\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1260, loss: 0.011761\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1270, loss: 0.012442\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1280, loss: 0.016847\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1290, loss: 0.012666\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1300, loss: 0.011462\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1310, loss: 0.010888\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1320, loss: 0.010558\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1330, loss: 0.010318\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1340, loss: 0.010137\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1350, loss: 0.009972\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1360, loss: 0.009799\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1370, loss: 0.009634\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1380, loss: 0.009474\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1390, loss: 0.009332\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1400, loss: 0.009587\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1410, loss: 0.038746\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 1420, loss: 0.010472\n","Testset: Precision: 0.919, recall: 0.971, F1-measure: 0.944, acc:0.902\n","\n","itr: 1430, loss: 0.010571\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1440, loss: 0.009567\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1450, loss: 0.008432\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1460, loss: 0.008412\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1470, loss: 0.008158\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1480, loss: 0.008015\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1490, loss: 0.007886\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1500, loss: 0.007753\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1510, loss: 0.007627\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1520, loss: 0.007503\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1530, loss: 0.007381\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1540, loss: 0.007261\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1550, loss: 0.007142\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1560, loss: 0.007026\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1570, loss: 0.006911\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1580, loss: 0.006798\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1590, loss: 0.006686\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1600, loss: 0.006577\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1610, loss: 0.006469\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1620, loss: 0.006362\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1630, loss: 0.006258\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1640, loss: 0.006154\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1650, loss: 0.006053\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1660, loss: 0.005953\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1670, loss: 0.005855\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1680, loss: 0.005758\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1690, loss: 0.005662\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1700, loss: 0.005569\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1710, loss: 0.005476\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1720, loss: 0.005386\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1730, loss: 0.005296\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1740, loss: 0.005208\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1750, loss: 0.005122\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1760, loss: 0.005037\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1770, loss: 0.004953\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1780, loss: 0.004871\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1790, loss: 0.004790\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1800, loss: 0.004711\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1810, loss: 0.004632\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1820, loss: 0.004556\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1830, loss: 0.004480\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1840, loss: 0.004406\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1850, loss: 0.004333\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1860, loss: 0.004261\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1870, loss: 0.004190\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1880, loss: 0.004121\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1890, loss: 0.004053\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1900, loss: 0.003986\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1910, loss: 0.003920\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1920, loss: 0.003855\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1930, loss: 0.003792\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1940, loss: 0.003729\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1950, loss: 0.003668\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1960, loss: 0.003608\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1970, loss: 0.003549\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1980, loss: 0.003490\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 1990, loss: 0.003433\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n"]}]},{"cell_type":"code","source":["mlp_l1 = MLP_L1('../data/BGL/text-tfidf-template-BGL.log.structured2_l1.npz')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cx9encJdSuIB","executionInfo":{"status":"ok","timestamp":1697930695484,"user_tz":240,"elapsed":18,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"outputId":"b73530a2-496f-4742-dd67-4e82ec6d7773"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(163, 2)\n","(163,)\n","positive: 143\n","ratio: 1.1398601398601398\n","Net(\n","  (hidden1): Linear(in_features=2, out_features=200, bias=True)\n","  (hidden2): Linear(in_features=200, out_features=200, bias=True)\n","  (output): Linear(in_features=200, out_features=2, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["loss_list, precision_list, recall_list, f1_list, accuracy_list = mlp.train_eval()"],"metadata":{"id":"Orv0leS3TyyF","executionInfo":{"status":"ok","timestamp":1697930718615,"user_tz":240,"elapsed":23145,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e687df89-6a89-4a04-ecb4-ddec85f7121e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["itr: 0, loss: 0.003377\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 10, loss: 0.003322\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 20, loss: 0.003268\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 30, loss: 0.003215\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 40, loss: 0.003163\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 50, loss: 0.003111\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 60, loss: 0.003061\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 70, loss: 0.003012\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 80, loss: 0.002963\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 90, loss: 0.002915\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 100, loss: 0.002868\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 110, loss: 0.002822\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 120, loss: 0.002777\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 130, loss: 0.002733\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 140, loss: 0.002689\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 150, loss: 0.002646\n","Testset: Precision: 0.941, recall: 0.914, F1-measure: 0.928, acc:0.878\n","\n","itr: 160, loss: 0.002604\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 170, loss: 0.002563\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 180, loss: 0.002523\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 190, loss: 0.002483\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 200, loss: 0.002444\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 210, loss: 0.002405\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 220, loss: 0.002368\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 230, loss: 0.002331\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 240, loss: 0.002294\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 250, loss: 0.002259\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 260, loss: 0.002224\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 270, loss: 0.002189\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 280, loss: 0.002156\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 290, loss: 0.002123\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 300, loss: 0.002090\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 310, loss: 0.002058\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 320, loss: 0.002027\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 330, loss: 0.001996\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 340, loss: 0.001966\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 350, loss: 0.001936\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 360, loss: 0.001907\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 370, loss: 0.001878\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 380, loss: 0.001850\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 390, loss: 0.001822\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 400, loss: 0.001795\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 410, loss: 0.001768\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 420, loss: 0.001742\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 430, loss: 0.001716\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 440, loss: 0.001691\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 450, loss: 0.001666\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 460, loss: 0.001642\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 470, loss: 0.001618\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 480, loss: 0.001594\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 490, loss: 0.001571\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 500, loss: 0.001548\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 510, loss: 0.001526\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 520, loss: 0.001504\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 530, loss: 0.001482\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 540, loss: 0.001461\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 550, loss: 0.001440\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 560, loss: 0.001420\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 570, loss: 0.001400\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 580, loss: 0.001380\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 590, loss: 0.001360\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 600, loss: 0.001341\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 610, loss: 0.001323\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 620, loss: 0.001304\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 630, loss: 0.001286\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 640, loss: 0.001268\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 650, loss: 0.001250\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 660, loss: 0.001233\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 670, loss: 0.001216\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 680, loss: 0.001200\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 690, loss: 0.001183\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 700, loss: 0.001167\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 710, loss: 0.001151\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 720, loss: 0.001135\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 730, loss: 0.001120\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 740, loss: 0.001105\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 750, loss: 0.001090\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 760, loss: 0.001076\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 770, loss: 0.001061\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 780, loss: 0.001047\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 790, loss: 0.001033\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 800, loss: 0.001019\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 810, loss: 0.001006\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 820, loss: 0.000993\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 830, loss: 0.000980\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 840, loss: 0.000967\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 850, loss: 0.000954\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 860, loss: 0.000942\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 870, loss: 0.000930\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 880, loss: 0.000918\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 890, loss: 0.000906\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 900, loss: 0.000894\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 910, loss: 0.000883\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 920, loss: 0.000871\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 930, loss: 0.000860\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 940, loss: 0.000849\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 950, loss: 0.000838\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 960, loss: 0.000828\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 970, loss: 0.000817\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 980, loss: 0.000807\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 990, loss: 0.000797\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1000, loss: 0.000787\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1010, loss: 0.000777\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1020, loss: 0.000768\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1030, loss: 0.000758\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1040, loss: 0.000749\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1050, loss: 0.000740\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1060, loss: 0.000730\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1070, loss: 0.000721\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1080, loss: 0.000713\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1090, loss: 0.000704\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1100, loss: 0.000695\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1110, loss: 0.000687\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1120, loss: 0.000679\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1130, loss: 0.000671\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1140, loss: 0.000662\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1150, loss: 0.000655\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1160, loss: 0.000647\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1170, loss: 0.000639\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1180, loss: 0.000631\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1190, loss: 0.000624\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1200, loss: 0.000617\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1210, loss: 0.000609\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1220, loss: 0.000602\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1230, loss: 0.000595\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1240, loss: 0.000588\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1250, loss: 0.000581\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1260, loss: 0.000575\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1270, loss: 0.000568\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1280, loss: 0.000561\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1290, loss: 0.000555\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1300, loss: 0.000548\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1310, loss: 0.000542\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1320, loss: 0.000536\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1330, loss: 0.000530\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1340, loss: 0.000524\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1350, loss: 0.000518\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1360, loss: 0.000512\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1370, loss: 0.000506\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1380, loss: 0.000500\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1390, loss: 0.000495\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1400, loss: 0.000489\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1410, loss: 0.000484\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1420, loss: 0.000478\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1430, loss: 0.000473\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1440, loss: 0.000468\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1450, loss: 0.000463\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1460, loss: 0.000458\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1470, loss: 0.000453\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1480, loss: 0.000448\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1490, loss: 0.000443\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1500, loss: 0.000438\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1510, loss: 0.000433\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1520, loss: 0.000428\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1530, loss: 0.000424\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1540, loss: 0.000419\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1550, loss: 0.000415\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1560, loss: 0.000410\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1570, loss: 0.000406\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1580, loss: 0.000401\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1590, loss: 0.000397\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1600, loss: 0.000393\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1610, loss: 0.000389\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1620, loss: 0.000385\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1630, loss: 0.000380\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1640, loss: 0.000376\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1650, loss: 0.000372\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1660, loss: 0.000369\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1670, loss: 0.000365\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1680, loss: 0.000361\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1690, loss: 0.000357\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1700, loss: 0.000353\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1710, loss: 0.000350\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1720, loss: 0.000346\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1730, loss: 0.000343\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1740, loss: 0.000339\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1750, loss: 0.000335\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1760, loss: 0.000332\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1770, loss: 0.000329\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1780, loss: 0.000325\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1790, loss: 0.000322\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1800, loss: 0.000319\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1810, loss: 0.000315\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1820, loss: 0.000312\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1830, loss: 0.000309\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1840, loss: 0.000306\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1850, loss: 0.000303\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1860, loss: 0.000300\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1870, loss: 0.000297\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1880, loss: 0.000294\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1890, loss: 0.000291\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1900, loss: 0.000288\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1910, loss: 0.000285\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1920, loss: 0.000282\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1930, loss: 0.000280\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1940, loss: 0.000277\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1950, loss: 0.000274\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1960, loss: 0.000271\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1970, loss: 0.000269\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1980, loss: 0.000266\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n","itr: 1990, loss: 0.000263\n","Testset: Precision: 0.914, recall: 0.914, F1-measure: 0.914, acc:0.854\n","\n"]}]},{"cell_type":"code","source":["print(precision_list[-1])\n","print(recall_list[-1])\n","print(f1_list[-1])\n","print(accuracy_list[-1])"],"metadata":{"id":"neiRpl8hT6YC","executionInfo":{"status":"ok","timestamp":1697930718616,"user_tz":240,"elapsed":16,"user":{"displayName":"Alexis Brissard","userId":"01552848406770931061"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3b7f3da3-8bf4-4bc7-cc72-207a595d95ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9142857142857143\n","0.9142857142857143\n","0.9142857142857143\n","tensor(0.8537)\n"]}]}]}